(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{313:function(t,a,s){"use strict";s.r(a);var v=s(10),_=Object(v.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"机器学习入门"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#机器学习入门"}},[t._v("#")]),t._v(" 机器学习入门")]),t._v(" "),a("p",[t._v("本文根据《深度学习入门：基于Python的理论与实现》一书总结，这本书非常适合深度学习入门学习，0基础也可以看懂。")]),t._v(" "),a("h2",{attrs:{id:"神经网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[t._v("#")]),t._v(" 神经网络")]),t._v(" "),a("h3",{attrs:{id:"mnist数据集"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mnist数据集"}},[t._v("#")]),t._v(" MNIST数据集")]),t._v(" "),a("p",[t._v("MNIST数据集是由0-9的数字图像构成的，训练图像有6万张，测试图像有1万张。一般的使用方法是，先用训练图像进行学习，再用学习到的模型度量能在多大程度上对测试图像进行正确的分类。")]),t._v(" "),a("p",[t._v("MNIST图像数据是28像素×28像素的灰度图像（1通道），各个像素取值在0-255之间，每个图像数据都有7、2、1等数字标签。")]),t._v(" "),a("p",[t._v("MNIST数据集用于手写数字识别，可以说是Deep Learning的Hello World!")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://stag-blog.oss-cn-beijing.aliyuncs.com/picture/image-20251111145423048.png",alt:"image-20251111145423048"}})]),t._v(" "),a("h2",{attrs:{id:"神经网络的学习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#神经网络的学习"}},[t._v("#")]),t._v(" 神经网络的学习")]),t._v(" "),a("h3",{attrs:{id:"基本概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基本概念"}},[t._v("#")]),t._v(" 基本概念")]),t._v(" "),a("p",[t._v("学习的目的是以损失函数为基础，找出能使它的值达到最小的权重参数。实际的神经网络中，参数的数量成千上万，在层数更深的深度学习中，参数的数量可能上亿，想要人工决定这些参数是不可能的，需要用数据来决定。")]),t._v(" "),a("p",[t._v("计算机视觉特征提取算法：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("SIFT（尺度不变特征变换）")]),t._v("：主打 “尺度 + 旋转不变性”，能在不同大小、旋转角度的图像中找到相同特征，抗光照、噪声能力强，是经典的通用特征提取算法。")]),t._v(" "),a("li",[a("strong",[t._v("SURF（加速稳健特征）")]),t._v("：SIFT 的优化版，通过近似计算提升速度，同时保留了尺度和旋转不变性，适合对实时性有要求的场景。")]),t._v(" "),a("li",[a("strong",[t._v("HOG（方向梯度直方图）")]),t._v("：专注于 “形状与边缘” 特征，通过统计图像局部区域的梯度方向分布来描述目标轮廓，尤其适合行人检测等刚性目标识别。")])]),t._v(" "),a("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://stag-blog.oss-cn-beijing.aliyuncs.com/picture/image-20251111152257919.png",alt:"image-20251111152257919"}}),t._v(" "),a("p",[t._v("机器学习中，一般将数据分为训练数据和测试数据。首先使用训练数据进行学习，寻找最优的参数；然后使用测试数据评价训练的到的模型的实际泛化能力。训练数据也称为"),a("strong",[t._v("监督数据")]),t._v("。")]),t._v(" "),a("p",[t._v("仅用一个数据集去学习和评价参数，是无法进行正确评价的。这会导致可以顺利处理某个数据集，但不能处理其他数据集。只对一个数据集过度拟合的状态称为"),a("strong",[t._v("过拟合")]),t._v("。")]),t._v(" "),a("h3",{attrs:{id:"损失函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#损失函数"}},[t._v("#")]),t._v(" 损失函数")]),t._v(" "),a("p",[t._v("损失函数是表示神经网络性能好坏的指标，即当前的神经网络对监督数据在多大程度上不拟合，一般用"),a("strong",[t._v("均方误差")]),t._v("和"),a("strong",[t._v("交叉熵误差")]),t._v("等。")]),t._v(" "),a("p",[a("strong",[t._v("one-hot编码")]),t._v("：是一种将离散特征转换为二进制向量的编码方式，核心思想是为每一个唯一的离散值分配一个独立的维度，并用和1表示该特征是否属于某个类别。")]),t._v(" "),a("p",[t._v("假设存在一个离散特征的取值集合为 "),a("code",[t._v("{A, B, C, D}")]),t._v("，则每个取值的 one-hot 编码如下：")]),t._v(" "),a("ul",[a("li",[t._v("A → [1, 0, 0, 0]")]),t._v(" "),a("li",[t._v("B → [0, 1, 0, 0]")]),t._v(" "),a("li",[t._v("C → [0, 0, 1, 0]")]),t._v(" "),a("li",[t._v("D → [0, 0, 0, 1]")])]),t._v(" "),a("p",[a("strong",[t._v("均方误差")]),t._v("：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://stag-blog.oss-cn-beijing.aliyuncs.com/picture/image-20251111154759841.png",alt:"image-20251111154759841"}})]),t._v(" "),a("p",[a("strong",[t._v("交叉熵误差")]),t._v("：tk中只有正确解标签的索引为1，单个数据和N个数据的公式如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://stag-blog.oss-cn-beijing.aliyuncs.com/picture/image-20251111154744785.png",alt:"image-20251111154744785"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://stag-blog.oss-cn-beijing.aliyuncs.com/picture/image-20251111155412458.png",alt:"image-20251111155412458"}})]),t._v(" "),a("h3",{attrs:{id:"梯度下降法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#梯度下降法"}},[t._v("#")]),t._v(" 梯度下降法")]),t._v(" "),a("p",[t._v("神经网络一般用梯度下降法寻找损失函数的最小值。代码实现求梯度，等同于求多个偏导数，偏导数的计算可以用数值微分解决。")]),t._v(" "),a("p",[a("strong",[t._v("学习率")]),t._v("：梯度下降法中控制模型参数更新步长的超参数，决定了每次迭代时模型向最优解靠近的幅度。学习率的选择很重要，过大过小都不行。")]),t._v(" "),a("p",[t._v("神经网络的学习步骤：")]),t._v(" "),a("ul",[a("li",[t._v("步骤1：mini-batch 从训练数据中随机选出一部分数据，称为mini-batch，目标是减小损失函数的值")]),t._v(" "),a("li",[t._v("步骤2：计算梯度，表示损失函数减小最多的方向")]),t._v(" "),a("li",[t._v("步骤3：更新参数：将权重参数沿梯度方向进行微小更新")]),t._v(" "),a("li",[t._v("步骤4：重复步骤1、步骤2、步骤3")])]),t._v(" "),a("h2",{attrs:{id:"误差反向传播法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#误差反向传播法"}},[t._v("#")]),t._v(" 误差反向传播法")]),t._v(" "),a("p",[t._v("反向传播传递“局部倒数”。")]),t._v(" "),a("p",[t._v("计算图中途求得的导数的结果可以被共享，从而可以高效地计算多个导数。")]),t._v(" "),a("p",[t._v("链式法则是关于复合函数的导数的性质。")]),t._v(" "),a("p",[t._v("反向传播：")]),t._v(" "),a("ul",[a("li",[t._v("加法节点的反向传播将上游的值传给下游，不需要正向传播的输入信号。")]),t._v(" "),a("li",[t._v("乘法的反向传播将上游的值乘以正向传播的翻转值传递给下游，需要正向传播的输入信号值。")])]),t._v(" "),a("h2",{attrs:{id:"卷积神经网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#卷积神经网络"}},[t._v("#")]),t._v(" 卷积神经网络")]),t._v(" "),a("h2",{attrs:{id:"深度学习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#深度学习"}},[t._v("#")]),t._v(" 深度学习")]),t._v(" "),a("p",[t._v("深度学习与机器学习的区别：")]),t._v(" "),a("h2",{attrs:{id:"报错解决"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#报错解决"}},[t._v("#")]),t._v(" 报错解决")]),t._v(" "),a("h3",{attrs:{id:"pycharm中使用matplotlib可视化数据时"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pycharm中使用matplotlib可视化数据时"}},[t._v("#")]),t._v(" Pycharm中使用matplotlib可视化数据时")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("AttributeError: 'FigureCanvasInterAgg' object has no attribute 'tostring_rgb'. Did you mean: 'tostring_argb'?\n")])])]),a("p",[t._v("在Pycharm设置中的Tools->Python Plots取消下面两个选项就可解决")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://stag-blog.oss-cn-beijing.aliyuncs.com/picture/image-20251111170740768.png",alt:"image-20251111170740768"}})]),t._v(" "),a("p",[t._v("110页")])])}),[],!1,null,null,null);a.default=_.exports}}]);